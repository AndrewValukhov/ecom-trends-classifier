{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee3a13e-91ea-4991-aa33-4fea500ce896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2599c2d-acc0-4ff3-88b4-9b24837f9880",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45152274-782c-4b5a-abdd-b9b6c158ee1e",
   "metadata": {},
   "source": [
    "Загрузим модель с HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b8476d-406e-47a9-9bb4-d38fe472e730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrejvaluhov/opt/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "classifier = pipeline(\"text-classification\",\n",
    "                     'Maldopast/bge-ecom-trends-classifier',\n",
    "                      device=device,\n",
    "                      batch_size=16,\n",
    "                      return_all_scores=True,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d4cfddd-a2e5-457f-a69b-0a1acdf1eb0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train = pd.read_csv('data/prepared_train.csv', index_col=[0])\n",
    "data = DatasetDict.load_from_disk('data/train_valid_split_prepared')\n",
    "trend_names = pd.read_csv('data/trend_names.csv')['0'].to_list()\n",
    "id2label = {k:v for k, v in enumerate(trend_names)}\n",
    "label2id = {v:k for k, v in id2label.items()}\n",
    "valid_df = data['validation'].to_pandas()\n",
    "test_df = pd.read_csv('data/prepared_test.csv')\n",
    "test_df['text'] = test_df['text'].fillna('')\n",
    "test_data = Dataset.from_pandas(test_df)\n",
    "sample_sub = pd.read_csv('data/sample_submission.csv')\n",
    "train_common = pd.read_csv('data/train_common.csv').set_index('text')['id_labels'].to_dict()\n",
    "train_common = {k:eval(v) for k,v in train_common.items()}\n",
    "train_common = {k: sorted(v) for k, v in train_common.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e443786a-bf4f-49a4-8bbe-d3803522b4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_preds(classifier, data, text_col='text', trend_names=trend_names):\n",
    "    \n",
    "    \"\"\"Функция для получения предсказаний на валидационной части датасета\"\"\"\n",
    "    \n",
    "    valid_preds = classifier(data['validation'][text_col])\n",
    "    scores = []\n",
    "    for row_pred in valid_preds:\n",
    "        row_scores = []\n",
    "        for d in row_pred:\n",
    "            row_scores.append(d['score'])\n",
    "        scores.append(row_scores)\n",
    "    valid_preds_df = pd.DataFrame(scores, columns=trend_names)\n",
    "    return valid_preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a43578f5-448d-4654-8786-26e5df23d2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts_preds_general(preds, ts=0.5):\n",
    "\n",
    "    \"\"\"Проходимся по массивам с предсказаниями, если они выше порога, добавляем в предсказанные лейблы\"\"\"\n",
    "\n",
    "    selected_preds = []\n",
    "    for p in preds:\n",
    "        row_pred = []\n",
    "        for d in p:\n",
    "            if d['score'] > ts:\n",
    "                row_pred.append(label2id[d['label']])\n",
    "        if row_pred == []:\n",
    "            max_p = 0\n",
    "            idx = 0\n",
    "            for d in p:\n",
    "                if d['score'] > max_p:\n",
    "                    max_p = d['score']\n",
    "                    idx = label2id[d['label']]\n",
    "            row_pred.append(idx)\n",
    "        selected_preds.append(row_pred)\n",
    "\n",
    "    return selected_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cd90da7-0101-4640-9a26-a7b4bfee1bf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = classifier('ghbd')[0]\n",
    "probs = np.array([d['score'] for d in p]) > 0.55\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f10d5fb0-a419-49f6-b21c-dd9cee53936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_dict = {d['label']: d['score'] for d in p}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e1e35f6-5d13-4eb4-8752-a6833e1692d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(probs_dict, orient='index').reset_index()\n",
    "df.columns = ['Тренд', 'Вероятность']\n",
    "df = df.sort_values('Вероятность', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "333bffba-8df5-4d95-a4e7-7c1fecd29f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19    0.109557\n",
       "18    0.015978\n",
       "0     0.009375\n",
       "20    0.005738\n",
       "2     0.005079\n",
       "Name: Вероятность, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Вероятность'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618e5690-7449-49b2-9aec-bf8a817d7c1d",
   "metadata": {},
   "source": [
    "Сделаем предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5a641af-8452-4ce7-aa19-2c96ab734e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds_df = get_valid_preds(classifier, data, text_col='text_mark')\n",
    "test_preds = classifier(test_data['text_mark'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0ef3306-7ccf-41ad-8578-05b6005884f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_common(preds):\n",
    "\n",
    "    \"\"\"Функция для проверки нахождения текста в обучающей выборке и проставление точно таких же меток, как в трейне\"\"\"\n",
    "    \n",
    "    for n, text in enumerate(test_df['text'].values):\n",
    "        if text in train_common.keys():\n",
    "            if preds[n] != train_common[text]:\n",
    "                print(n, preds[n], train_common[text])\n",
    "                preds[n] = train_common[text]\n",
    "                print('*' * 30)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c61b8852-c5d2-493a-be0e-bc81bd6e9284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_df(preds, sub, ts=0.5, ind_dict=None, common=False):\n",
    "\n",
    "    \"\"\"Функция для получения датафрейма с предсказаниями\"\"\"\n",
    "\n",
    "    sub_ = sub.copy()\n",
    "    \n",
    "    if ind_dict:\n",
    "        preds = get_ts_preds(preds, ind_dict)\n",
    "    else:\n",
    "        preds = get_ts_preds_general(preds, ts)\n",
    "\n",
    "    if common:\n",
    "        preds = check_common(preds)\n",
    "\n",
    "    sub_['target'] = pd.Series(preds).apply(lambda x: ' '.join(str(n) for n in x))\n",
    "    display(sub_['target'].apply(lambda x: len(x.split(' '))).value_counts())\n",
    "    return sub_, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec33746-7c62-45f4-80aa-a1ecbadd982f",
   "metadata": {},
   "source": [
    "Выберем порог 0.55 как более строгий, чем просто 0.5 (эвристика)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0677bede-17a7-445c-953e-0267acf988ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "627 [20] [19]\n",
      "******************************\n",
      "718 [20] [19]\n",
      "******************************\n",
      "751 [20] [19]\n",
      "******************************\n",
      "885 [19] [18]\n",
      "******************************\n",
      "1008 [20] [19]\n",
      "******************************\n",
      "1172 [20] [19]\n",
      "******************************\n",
      "1957 [20] [19]\n",
      "******************************\n",
      "3096 [20] [19]\n",
      "******************************\n",
      "3142 [20] [19]\n",
      "******************************\n",
      "3461 [20] [19]\n",
      "******************************\n",
      "3776 [18] [19]\n",
      "******************************\n",
      "3944 [19] [18]\n",
      "******************************\n",
      "4207 [20] [19]\n",
      "******************************\n",
      "4385 [20] [19]\n",
      "******************************\n",
      "4844 [20] [19]\n",
      "******************************\n",
      "5080 [20] [19]\n",
      "******************************\n",
      "5244 [19] [18]\n",
      "******************************\n",
      "5610 [20] [19]\n",
      "******************************\n",
      "7219 [20] [19]\n",
      "******************************\n",
      "7253 [19] [18]\n",
      "******************************\n",
      "7329 [20] [19]\n",
      "******************************\n",
      "7904 [20] [19]\n",
      "******************************\n",
      "8148 [20] [19]\n",
      "******************************\n",
      "8332 [18] [20]\n",
      "******************************\n",
      "8476 [20] [19]\n",
      "******************************\n",
      "8515 [19] [18]\n",
      "******************************\n",
      "8857 [20] [19]\n",
      "******************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    5956\n",
       "2    2354\n",
       "3     598\n",
       "4     100\n",
       "5       6\n",
       "6       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_df, prs = get_pred_df(test_preds, sample_sub, ts=0.55, common=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "918ad21a-aaae-427c-946e-68d7de3b5239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5956\n",
       "2    2354\n",
       "3     598\n",
       "4     100\n",
       "5       6\n",
       "6       1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загрузим сабмит, который дал лучший скор\n",
    "best_df = pd.read_csv('data/deepvk_stw_text_mark_gen_055_fulltr_common.csv')\n",
    "best_df['target'].apply(lambda x: len(x.split())).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89c876a-7384-4d96-8075-58a7ca27dfbb",
   "metadata": {},
   "source": [
    "проверим, что полученные предсказания с помощью модели соответствуют предсказаниям лучшего сабмита"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a95341e-ac67-4172-97cb-b1c6164c24dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index     9015\n",
       "target    9015\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(gen_df == best_df).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9572d6ef-1020-4d4d-acf7-762cfd7b7e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_df.to_csv('data/best_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afbdaa8-dc0e-44e8-9969-ee0a307cd22d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
